{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 288\n",
    "n_layers = 6\n",
    "n_heads = 6\n",
    "multiple_of = 32\n",
    "dropout = 0.0\n",
    "\n",
    "batch_size = 2  # if gradient_accumulation_steps > 1, this is the micro-batch size\n",
    "max_seq_len = 256\n",
    "\n",
    "\n",
    "model_args = dict(\n",
    "    dim=dim,\n",
    "    n_layers=n_layers,\n",
    "    n_heads=n_heads,\n",
    "    n_kv_heads=n_heads,\n",
    "    vocab_size=32000,\n",
    "    multiple_of=multiple_of,\n",
    "    max_seq_len=max_seq_len,\n",
    "    #dropout=dropout,\n",
    "    softmax=\"softmax1\",\n",
    "    flash=False,\n",
    "\n",
    ")\n",
    "\n",
    "# model_args=dict(dim=768, n_layers=12, n_heads=12, \n",
    "#                 n_kv_heads=12, vocab_size=32000, multiple_of=32, \n",
    "#                 norm_eps=1e-05, max_seq_len=1024, dropout=0.0, \n",
    "#                 add_zero_attn=False, softmax='softmax1', flash=False)\n",
    "\n",
    "model_args = ModelArgs(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.compile(model)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn(module, input, output):\n",
    "    \"Hook function to store outputs in a .output attribute\"\n",
    "    if hasattr(module, \"max_att\"):\n",
    "        module.max_att = max(output.detach().max(), module.max_att)\n",
    "    else:\n",
    "        module.max_att = output.detach().max()\n",
    "    print(module.max_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_hooks(model):\n",
    "    hook_handles = []\n",
    "    for b in model.layers:\n",
    "        hook_handles.append(b.attention.register_forward_hook(hook_fn))\n",
    "    return hook_handles\n",
    "\n",
    "handles = add_hooks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, model_args.vocab_size, (batch_size, model_args.max_seq_len) )\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0571)\n",
      "tensor(0.0575)\n",
      "tensor(0.0736)\n",
      "tensor(0.0824)\n",
      "tensor(0.0726)\n",
      "tensor(0.1038)\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(l.attention.max_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am capatin Hook\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.7607], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "m = torch.nn.Linear(2,1)\n",
    "\n",
    "m.register_forward_hook(lambda m,i,o: print(\"I am capatin Hook\"))\n",
    "\n",
    "# works as expexted\n",
    "m(torch.randn(2))\n",
    "\n",
    "# does not work\n",
    "m.forward(torch.randn(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randint(0, model_args.vocab_size, (batch_size, model_args.max_seq_len) )\n",
    "    out = model(x)\n",
    "    inf_norm, k = model.compute_attention_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.05343833565711975,\n",
       "  0.05626192316412926,\n",
       "  0.0662432461977005,\n",
       "  0.07274584472179413,\n",
       "  0.07878565788269043,\n",
       "  0.0826156884431839],\n",
       " [9.609243933664462,\n",
       "  2.1342359567583387,\n",
       "  0.6189443758403588,\n",
       "  -0.12834004447029024,\n",
       "  -0.016824915476210123,\n",
       "  0.009668920702321948])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_norm, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [b.attention.output for b in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4942e-02,  1.7280e-02, -7.3087e-03,  ..., -5.6646e-03,\n",
       "           2.7745e-02,  1.6313e-02],\n",
       "         [-2.5999e-02,  1.2745e-02, -3.5869e-03,  ..., -1.5707e-02,\n",
       "           1.2777e-02,  2.0607e-02],\n",
       "         [-1.8710e-02,  1.7124e-02, -4.9153e-03,  ...,  9.6869e-03,\n",
       "           3.3312e-03,  9.3342e-03],\n",
       "         ...,\n",
       "         [-1.4150e-03,  3.3449e-03, -4.0636e-03,  ..., -7.5439e-04,\n",
       "           3.7374e-04,  5.6159e-04],\n",
       "         [-1.3440e-03,  3.3190e-03, -4.2030e-03,  ...,  6.1608e-04,\n",
       "           1.8159e-04,  7.8880e-04],\n",
       "         [-1.9902e-03,  3.7543e-03, -4.6454e-03,  ..., -2.2938e-04,\n",
       "           3.7203e-04,  7.0601e-04]],\n",
       "\n",
       "        [[-1.4862e-02, -2.3684e-03, -3.0112e-02,  ...,  8.2180e-03,\n",
       "          -1.0275e-02,  1.0324e-02],\n",
       "         [-8.0560e-03,  5.2986e-03, -5.1081e-03,  ..., -8.5383e-03,\n",
       "           1.9722e-05,  1.7366e-02],\n",
       "         [-6.3437e-03,  8.5796e-03, -1.3878e-02,  ...,  3.0706e-03,\n",
       "           1.1113e-03,  1.3156e-02],\n",
       "         ...,\n",
       "         [ 1.4875e-03, -1.7900e-03,  7.6993e-04,  ..., -4.8807e-04,\n",
       "           1.6279e-03,  4.3445e-03],\n",
       "         [ 7.3248e-04, -1.5593e-03,  1.7429e-04,  ..., -3.1423e-04,\n",
       "           1.8258e-03,  4.5774e-03],\n",
       "         [ 1.2976e-03, -1.7389e-03, -2.6027e-04,  ..., -6.0402e-04,\n",
       "           1.5521e-03,  4.6057e-03]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.876882591728345,\n",
       " 2.360544078376952,\n",
       " 0.9361386662094842,\n",
       " 0.2454783971266279,\n",
       " 0.4035440196696536,\n",
       " -0.017442972684702074]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[kurtosis(o.flatten()) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.tensor([kurtosis(o.flatten().cpu().float()) for o in outputs]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
